{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Used environment: `PaperGPT` (in `environment.yml`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): / WARNING conda.models.version:get_matcher(544): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\n",
      "done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.11.1\n",
      "  latest version: 23.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.9.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /users/cwoest/Applications/anaconda3/envs/PaperGPT\n",
      "\n",
      "  added / updated specs:\n",
      "    - openai\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    click-8.1.7                |unix_pyh707e725_0          82 KB  conda-forge\n",
      "    et_xmlfile-1.1.0           |     pyhd8ed1ab_0          10 KB  conda-forge\n",
      "    openpyxl-3.1.2             |  py311h2725bcf_1         657 KB  conda-forge\n",
      "    pandas-stubs-2.1.1.230928  |     pyhd8ed1ab_0          94 KB  conda-forge\n",
      "    protobuf-3.20.3            |  py311h814d153_1         344 KB  conda-forge\n",
      "    setproctitle-1.3.3         |  py311h2725bcf_0          18 KB  conda-forge\n",
      "    types-pytz-2023.3.1.1      |     pyhd8ed1ab_0          18 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  appdirs            conda-forge/noarch::appdirs-1.4.4-pyh9f0ad1d_0 \n",
      "  click              conda-forge/noarch::click-8.1.7-unix_pyh707e725_0 \n",
      "  colorama           conda-forge/noarch::colorama-0.4.6-pyhd8ed1ab_0 \n",
      "  docker-pycreds     conda-forge/noarch::docker-pycreds-0.4.0-py_0 \n",
      "  et_xmlfile         conda-forge/noarch::et_xmlfile-1.1.0-pyhd8ed1ab_0 \n",
      "  gitdb              conda-forge/noarch::gitdb-4.0.10-pyhd8ed1ab_0 \n",
      "  gitpython          conda-forge/noarch::gitpython-3.1.37-pyhd8ed1ab_0 \n",
      "  openai             conda-forge/noarch::openai-0.28.1-pyhd8ed1ab_0 \n",
      "  openpyxl           conda-forge/osx-64::openpyxl-3.1.2-py311h2725bcf_1 \n",
      "  pandas-stubs       conda-forge/noarch::pandas-stubs-2.1.1.230928-pyhd8ed1ab_0 \n",
      "  pathtools          conda-forge/noarch::pathtools-0.1.2-py_1 \n",
      "  plotly             conda-forge/noarch::plotly-5.17.0-pyhd8ed1ab_0 \n",
      "  protobuf           conda-forge/osx-64::protobuf-3.20.3-py311h814d153_1 \n",
      "  sentry-sdk         conda-forge/noarch::sentry-sdk-1.31.0-pyhd8ed1ab_0 \n",
      "  setproctitle       conda-forge/osx-64::setproctitle-1.3.3-py311h2725bcf_0 \n",
      "  smmap              conda-forge/noarch::smmap-3.0.5-pyh44b312d_0 \n",
      "  tenacity           conda-forge/noarch::tenacity-8.2.3-pyhd8ed1ab_0 \n",
      "  types-pytz         conda-forge/noarch::types-pytz-2023.3.1.1-pyhd8ed1ab_0 \n",
      "  wandb              conda-forge/noarch::wandb-0.15.12-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openpyxl-3.1.2       | 657 KB    |                                       |   0% \n",
      "protobuf-3.20.3      | 344 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "et_xmlfile-1.1.0     | 10 KB     |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "types-pytz-2023.3.1. | 18 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "setproctitle-1.3.3   | 18 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "click-8.1.7          | 82 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pandas-stubs-2.1.1.2 | 94 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "protobuf-3.20.3      | 344 KB    | #7                                    |   5% \u001b[A\n",
      "\n",
      "et_xmlfile-1.1.0     | 10 KB     | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "types-pytz-2023.3.1. | 18 KB     | ################################6     |  88% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "setproctitle-1.3.3   | 18 KB     | ################################5     |  88% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "click-8.1.7          | 82 KB     | #######1                              |  19% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "et_xmlfile-1.1.0     | 10 KB     | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pandas-stubs-2.1.1.2 | 94 KB     | ######2                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "openpyxl-3.1.2       | 657 KB    | 9                                     |   2% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "setproctitle-1.3.3   | 18 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "click-8.1.7          | 82 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "click-8.1.7          | 82 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "protobuf-3.20.3      | 344 KB    | ##################################### | 100% \u001b[A\n",
      "protobuf-3.20.3      | 344 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pandas-stubs-2.1.1.2 | 94 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge openai -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the raw text from the file\n",
    "\n",
    "First we need to extract the raw text from the file containing the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 15\n",
      "1st page: {'/Type': '/Page', '/Contents': [IndirectObject(101, 0, 5156558800), IndirectObject(5956, 0, 5156558800)], '/MediaBox': [0, 0, 612, 792], '/Parent': IndirectObject(109, 0, 5156558800), '/Resources': IndirectObject(100, 0, 5156558800)}\n",
      "1st page, number of chars: 2853\n"
     ]
    }
   ],
   "source": [
    "# Read the file if it's a PDF.\n",
    "reader = PdfReader(\"../tests/attention_is_all_you_need.pdf\")\n",
    "number_of_pages = len(reader.pages)\n",
    "page = reader.pages[0]\n",
    "text = page.extract_text()\n",
    "print(f\"Number of pages: {number_of_pages}\")\n",
    "print(f\"1st page: {page}\")\n",
    "print(f\"1st page, number of chars: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 100 chars: \n",
      "    Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and\n",
      "\n",
      "Last  100 chars: \n",
      "    ormation Processing Systems (NIPS 2017), Long Beach, CA, USA.arXiv:1706.03762v7  [cs.CL]  2 Aug 2023\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "print(f\"First {N} chars: \\n    {text[:N]}\\n\")\n",
    "print(f\"Last  {N} chars: \\n    {text[-N:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_per_page = {}\n",
    "\n",
    "# Save the raw text as value under the page_id key.\n",
    "for page_id in range(len(reader.pages)):\n",
    "    page = reader.pages[page_id]\n",
    "    raw_text_in_the_page = page.extract_text()\n",
    "    raw_text_per_page[page_id] = raw_text_in_the_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 Introduction\\nRecurrent neural networks, long short-term memory [ 13] and gated recurrent [ 7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 35,2,5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [ 21] and conditional\\ncomputation [ 32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [ 2,19]. In all but a few cases [ 27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2 Background\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [ 18] and ConvS2S [ 9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [ 12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., x n)to a sequence\\nof continuous representations z= (z1, ..., z n). Given z, the decoder then generates an output\\nsequence (y1, ..., y m)of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text_per_page.get(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the text\n",
    "\n",
    "Before we feed the LLM with the papers information we need to clean the extracted text. For that we need to perform some processing steps\n",
    "\n",
    "- [ ] Remove all unncessary and un-informative chars \n",
    "- [ ] Select which parts/pages contains which sections\n",
    "- [ ] Select only the relevant text for the main summarization\n",
    "- [ ] Create a dictionary with keys stating the section and values contains the cleaned text per section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BART\n",
    "\n",
    "https://huggingface.co/facebook/bart-large-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198a8bbbadff4827a0c6e05d686b7011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3c4fccc584478cad0d7019ad7ac894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a3575b2abc491eafc24a8e26bcd0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b269560a4c77436880250794567f8340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5850291ee3fb4fe9a2acd9f4450aad5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c201545c6e94fab921a84c64b2931c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(raw_text_per_page.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m summarizer(raw_text_per_page\u001b[38;5;241m.\u001b[39mget(page_id),\n\u001b[1;32m      2\u001b[0m         max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m130\u001b[39m, \n\u001b[1;32m      3\u001b[0m         min_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, \n\u001b[1;32m      4\u001b[0m         do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     )\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py:265\u001b[0m, in \u001b[0;36mSummarizationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=240'>241</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=241'>242</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=242'>243</a>\u001b[0m \u001b[39m    Summarize the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=243'>244</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=262'>263</a>\u001b[0m \u001b[39m          ids of the summary.\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=263'>264</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=264'>265</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py:165\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=135'>136</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=136'>137</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=137'>138</a>\u001b[0m \u001b[39m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=138'>139</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=161'>162</a>\u001b[0m \u001b[39m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=162'>163</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=164'>165</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=165'>166</a>\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=166'>167</a>\u001b[0m         \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=167'>168</a>\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(el, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m args[\u001b[39m0\u001b[39m])\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=168'>169</a>\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39mlen\u001b[39m(res) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=169'>170</a>\u001b[0m     ):\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=170'>171</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [res[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py:1129\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1120'>1121</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1121'>1122</a>\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1122'>1123</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1125'>1126</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1126'>1127</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1127'>1128</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1128'>1129</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py:1136\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1133'>1134</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1134'>1135</a>\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1135'>1136</a>\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1136'>1137</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1137'>1138</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py:1035\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1032'>1033</a>\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1033'>1034</a>\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1034'>1035</a>\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1035'>1036</a>\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1036'>1037</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py:187\u001b[0m, in \u001b[0;36mText2TextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=184'>185</a>\u001b[0m generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m generate_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mmax_length)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=185'>186</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_inputs(input_length, generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmin_length\u001b[39m\u001b[39m\"\u001b[39m], generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=186'>187</a>\u001b[0m output_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mgenerate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgenerate_kwargs)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=187'>188</a>\u001b[0m out_b \u001b[39m=\u001b[39m output_ids\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/text2text_generation.py?line=188'>189</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/utils/_contextlib.py?line=111'>112</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/utils/_contextlib.py?line=112'>113</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/utils/_contextlib.py?line=113'>114</a>\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/utils/_contextlib.py?line=114'>115</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py:1486\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1477'>1478</a>\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1478'>1479</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1479'>1480</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mgeneration results, please set `padding_side=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m'\u001b[39m\u001b[39m` when initializing the tokenizer.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1480'>1481</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1482'>1483</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m model_kwargs:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1483'>1484</a>\u001b[0m     \u001b[39m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1484'>1485</a>\u001b[0m     \u001b[39m# and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1485'>1486</a>\u001b[0m     model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_encoder_decoder_kwargs_for_generation(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1486'>1487</a>\u001b[0m         inputs_tensor, model_kwargs, model_input_name\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1487'>1488</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1489'>1490</a>\u001b[0m \u001b[39m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1490'>1491</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py:655\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=652'>653</a>\u001b[0m encoder_kwargs[\u001b[39m\"\u001b[39m\u001b[39mreturn_dict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=653'>654</a>\u001b[0m encoder_kwargs[model_input_name] \u001b[39m=\u001b[39m inputs_tensor\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=654'>655</a>\u001b[0m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39mencoder_outputs\u001b[39m\u001b[39m\"\u001b[39m]: ModelOutput \u001b[39m=\u001b[39m encoder(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mencoder_kwargs)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=656'>657</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:820\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py?line=816'>817</a>\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py?line=817'>818</a>\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_tokens(input_ids) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_scale\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py?line=819'>820</a>\u001b[0m embed_pos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_positions(\u001b[39minput\u001b[39m)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py?line=820'>821</a>\u001b[0m embed_pos \u001b[39m=\u001b[39m embed_pos\u001b[39m.\u001b[39mto(inputs_embeds\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py?line=822'>823</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m inputs_embeds \u001b[39m+\u001b[39m embed_pos\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py:139\u001b[0m, in \u001b[0;36mBartLearnedPositionalEmbedding.forward\u001b[0;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py?line=133'>134</a>\u001b[0m bsz, seq_len \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mshape[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py?line=134'>135</a>\u001b[0m positions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py?line=135'>136</a>\u001b[0m     past_key_values_length, past_key_values_length \u001b[39m+\u001b[39m seq_len, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdevice\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py?line=136'>137</a>\u001b[0m )\u001b[39m.\u001b[39mexpand(bsz, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/bart/modeling_bart.py?line=138'>139</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mforward(positions \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffset)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/sparse.py?line=160'>161</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/sparse.py?line=161'>162</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39membedding(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/sparse.py?line=162'>163</a>\u001b[0m         \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_idx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_norm,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/sparse.py?line=163'>164</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm_type, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_grad_by_freq, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/functional.py?line=2226'>2227</a>\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/functional.py?line=2227'>2228</a>\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/functional.py?line=2228'>2229</a>\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/functional.py?line=2229'>2230</a>\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/functional.py?line=2230'>2231</a>\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/functional.py?line=2231'>2232</a>\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/functional.py?line=2232'>2233</a>\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39membedding(weight, \u001b[39minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "summarizer(raw_text_per_page.get(page_id),\n",
    "        max_length=130, \n",
    "        min_length=30, \n",
    "        do_sample=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries per Page\n",
      "==================\n",
      "    Page 0\n",
      "    Page 1\n",
      "    Page 2\n",
      "    Page 3\n",
      "    Page 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Summaries per Page\")\n",
    "print(f\"==================\")\n",
    "\n",
    "summaries_per_page = {}\n",
    "\n",
    "# for page_id in range(len(list(raw_text_per_page.keys()))):\n",
    "for page_id in range(5):\n",
    "    print(f\"{4*' '}Page {page_id}\")\n",
    "    text = raw_text_per_page.get(page_id)\n",
    "\n",
    "    summary = summarizer(text, \n",
    "        max_length=130, \n",
    "        min_length=30, \n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    summaries_per_page[page_id] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms. The Transformer is superior in quality while being more parallelizable and requiring significantly less time to train.'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_per_page.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'The Transformer is the first transduction model relying solely on self-attention to compute representations of its input and output. It can reach a new state of the art in machine translation quality after being trained for as little as twelve hours on eight P100 GPUs. In the following sections, we will describe the Transformer, motivate patrioticself-att attention and discuss its advantages over models such as [17, 18] and [9].'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_per_page.get(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pygmalion-6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b57a82f2ed43629309da56491db1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/975 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15dac634790641d1b36800b7636c8a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/25.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4ceebf891347a3a43cf3587edb01eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6734e721f64c2d9147147c9947c8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/10.4G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06726f4eb45492ca6205ef4a1368076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/5.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe93a993fa94db284f397cfce06e07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff092f05928e433d8e83a435260caa3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/709 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5717fcf57bdc471a8a6ce09f93d85c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2950c9b473f8461caa20c06a72d76422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b793aa49a7ed49d39ea17c3405d14364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3975cd711b4cc6b3b517ab0be74276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/4.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3d9994b0094f5eb447c09252a4dee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/470 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline, Conversation\n",
    "\n",
    "pipe = pipeline(\"conversational\", model=\"PygmalionAI/pygmalion-6b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversation input is to long (711), trimming it to (20 - 10)\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conversation\n\u001b[1;32m      3\u001b[0m conversation \u001b[38;5;241m=\u001b[39m Conversation(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you summarize this in 1 sentence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_text_per_page\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m conversation \u001b[38;5;241m=\u001b[39m pipe(conversation)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py:243\u001b[0m, in \u001b[0;36mConversationalPipeline.__call__\u001b[0;34m(self, conversations, num_workers, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=222'>223</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=223'>224</a>\u001b[0m \u001b[39mGenerate responses for the conversation(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=224'>225</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=236'>237</a>\u001b[0m \u001b[39m    containing a new user input.\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=237'>238</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=238'>239</a>\u001b[0m \u001b[39m# XXX: num_workers==0 is required to be backward compatible\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=239'>240</a>\u001b[0m \u001b[39m# Otherwise the threads will require a Conversation copy.\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=240'>241</a>\u001b[0m \u001b[39m# This will definitely hinder performance on GPU, but has to be opted\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=241'>242</a>\u001b[0m \u001b[39m# in because of this BC change.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=242'>243</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(conversations, num_workers\u001b[39m=\u001b[39mnum_workers, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=243'>244</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(outputs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=244'>245</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py:1129\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1120'>1121</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1121'>1122</a>\u001b[0m         \u001b[39miter\u001b[39m(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1122'>1123</a>\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1125'>1126</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1126'>1127</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1127'>1128</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1128'>1129</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py:1136\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1133'>1134</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_single\u001b[39m(\u001b[39mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1134'>1135</a>\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1135'>1136</a>\u001b[0m     model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1136'>1137</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpostprocess(model_outputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpostprocess_params)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1137'>1138</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py:1035\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1032'>1033</a>\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1033'>1034</a>\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1034'>1035</a>\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1035'>1036</a>\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=1036'>1037</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py:280\u001b[0m, in \u001b[0;36mConversationalPipeline._forward\u001b[0;34m(self, model_inputs, minimum_tokens, **generate_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=277'>278</a>\u001b[0m conversation \u001b[39m=\u001b[39m model_inputs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mconversation\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=278'>279</a>\u001b[0m generate_kwargs[\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m max_length\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=279'>280</a>\u001b[0m output_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mgenerate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mgenerate_kwargs)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=280'>281</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/conversational.py?line=281'>282</a>\u001b[0m     start_position \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/utils/_contextlib.py?line=111'>112</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/utils/_contextlib.py?line=112'>113</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/utils/_contextlib.py?line=113'>114</a>\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/utils/_contextlib.py?line=114'>115</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py:1596\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1578'>1579</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39massisted_decoding(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1579'>1580</a>\u001b[0m         input_ids,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1580'>1581</a>\u001b[0m         assistant_model\u001b[39m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1591'>1592</a>\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1592'>1593</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1593'>1594</a>\u001b[0m \u001b[39mif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1594'>1595</a>\u001b[0m     \u001b[39m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1595'>1596</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgreedy_search(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1596'>1597</a>\u001b[0m         input_ids,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1597'>1598</a>\u001b[0m         logits_processor\u001b[39m=\u001b[39mlogits_processor,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1598'>1599</a>\u001b[0m         stopping_criteria\u001b[39m=\u001b[39mstopping_criteria,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1599'>1600</a>\u001b[0m         pad_token_id\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mpad_token_id,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1600'>1601</a>\u001b[0m         eos_token_id\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39meos_token_id,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1601'>1602</a>\u001b[0m         output_scores\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39moutput_scores,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1602'>1603</a>\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mreturn_dict_in_generate,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1603'>1604</a>\u001b[0m         synced_gpus\u001b[39m=\u001b[39msynced_gpus,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1604'>1605</a>\u001b[0m         streamer\u001b[39m=\u001b[39mstreamer,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1605'>1606</a>\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1606'>1607</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1608'>1609</a>\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=1609'>1610</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_kwargs[\u001b[39m\"\u001b[39m\u001b[39muse_cache\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py:2444\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=2440'>2441</a>\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=2442'>2443</a>\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=2443'>2444</a>\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=2444'>2445</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=2445'>2446</a>\u001b[0m     return_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=2446'>2447</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=2447'>2448</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=2448'>2449</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=2450'>2451</a>\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/generation/utils.py?line=2451'>2452</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py:855\u001b[0m, in \u001b[0;36mGPTJForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=846'>847</a>\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=847'>848</a>\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=848'>849</a>\u001b[0m \u001b[39m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=849'>850</a>\u001b[0m \u001b[39m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=850'>851</a>\u001b[0m \u001b[39m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=851'>852</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=852'>853</a>\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=854'>855</a>\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=855'>856</a>\u001b[0m     input_ids,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=856'>857</a>\u001b[0m     past_key_values\u001b[39m=\u001b[39mpast_key_values,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=857'>858</a>\u001b[0m     attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=858'>859</a>\u001b[0m     token_type_ids\u001b[39m=\u001b[39mtoken_type_ids,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=859'>860</a>\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=860'>861</a>\u001b[0m     head_mask\u001b[39m=\u001b[39mhead_mask,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=861'>862</a>\u001b[0m     inputs_embeds\u001b[39m=\u001b[39minputs_embeds,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=862'>863</a>\u001b[0m     use_cache\u001b[39m=\u001b[39muse_cache,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=863'>864</a>\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=864'>865</a>\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=865'>866</a>\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=866'>867</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=867'>868</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=869'>870</a>\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py:690\u001b[0m, in \u001b[0;36mGPTJModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=680'>681</a>\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=681'>682</a>\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=682'>683</a>\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=686'>687</a>\u001b[0m         head_mask[i],\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=687'>688</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=688'>689</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=689'>690</a>\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=690'>691</a>\u001b[0m         hidden_states\u001b[39m=\u001b[39mhidden_states,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=691'>692</a>\u001b[0m         layer_past\u001b[39m=\u001b[39mlayer_past,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=692'>693</a>\u001b[0m         attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=693'>694</a>\u001b[0m         position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=694'>695</a>\u001b[0m         head_mask\u001b[39m=\u001b[39mhead_mask[i],\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=695'>696</a>\u001b[0m         use_cache\u001b[39m=\u001b[39muse_cache,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=696'>697</a>\u001b[0m         output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=697'>698</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=699'>700</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=700'>701</a>\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py:321\u001b[0m, in \u001b[0;36mGPTJBlock.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, position_ids, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=317'>318</a>\u001b[0m attn_output \u001b[39m=\u001b[39m attn_outputs[\u001b[39m0\u001b[39m]  \u001b[39m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=318'>319</a>\u001b[0m outputs \u001b[39m=\u001b[39m attn_outputs[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=320'>321</a>\u001b[0m feed_forward_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(hidden_states)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=321'>322</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m attn_output \u001b[39m+\u001b[39m feed_forward_hidden_states \u001b[39m+\u001b[39m residual\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=323'>324</a>\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py:284\u001b[0m, in \u001b[0;36mGPTJMLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=281'>282</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_in(hidden_states)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=282'>283</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(hidden_states)\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=283'>284</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_out(hidden_states)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=284'>285</a>\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/gptj/modeling_gptj.py?line=285'>286</a>\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1515'>1516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1516'>1517</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1517'>1518</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1521'>1522</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1522'>1523</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1523'>1524</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1524'>1525</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1525'>1526</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1526'>1527</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1528'>1529</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/module.py?line=1529'>1530</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/linear.py?line=112'>113</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/torch/nn/modules/linear.py?line=113'>114</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mlinear(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Conversation\n",
    "\n",
    "conversation = Conversation(f\"Can you summarize this in 1 sentence: {raw_text_per_page.get(0)}\")\n",
    "conversation = pipe(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2-large')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3cfb551e6f46179bdbe17e8450454c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533f77774e714c45949e5a8344595257",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ae0af1c3af4089839bf9610f6414e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00950c4b09264a05869191b5db99f234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8e232af0e3463cbe9493482a58207c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2816b4995f645768d3a11cb3e3bff3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language model, but what I'm really doing is making a human-readable version of something with a deep, powerful and expressive\"},\n",
       " {'generated_text': \"Hello, I'm a language model, this is my first commit and I'm going to put it on github. I've also put my code in\"},\n",
       " {'generated_text': \"Hello, I'm a language model, and you'll hear me in this chapter!\\n\\nOne of the features we love is the ability to have\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a developer. If you don't know my code, please don't comment anything on the repo, because\"},\n",
       " {'generated_text': \"Hello, I'm a language model, I'm not a language designer. That should probably be a rule not a rule. I am speaking as a\"}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "generator = pipeline('text-generation', model='gpt2-large')\n",
    "set_seed(42)\n",
    "generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YAML configuration file\n",
    "with open(\"../config/config_private.yml\", \"r\") as config_file:\n",
    "    config_data = yaml.safe_load(config_file)\n",
    "\n",
    "# Extract the API key from the loaded data\n",
    "api_key = config_data[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m----> 6\u001b[0m completions \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      7\u001b[0m     engine\u001b[38;5;241m=\u001b[39mmodel_engine,\n\u001b[1;32m      8\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHallo Welt\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39mmax_tokens,\n\u001b[1;32m     10\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mtemperature\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get the summary from the first completion\u001b[39;00m\n\u001b[1;32m     14\u001b[0m summary \u001b[38;5;241m=\u001b[39m completions\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/completion.py?line=22'>23</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/completion.py?line=23'>24</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/completion.py?line=24'>25</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/completion.py?line=25'>26</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/completion.py?line=26'>27</a>\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=128'>129</a>\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=129'>130</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=130'>131</a>\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=137'>138</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=138'>139</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=139'>140</a>\u001b[0m     (\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=140'>141</a>\u001b[0m         deployment_id,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=141'>142</a>\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=151'>152</a>\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=152'>153</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=154'>155</a>\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=155'>156</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=156'>157</a>\u001b[0m         url,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=157'>158</a>\u001b[0m         params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=158'>159</a>\u001b[0m         headers\u001b[39m=\u001b[39mheaders,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=159'>160</a>\u001b[0m         stream\u001b[39m=\u001b[39mstream,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=160'>161</a>\u001b[0m         request_id\u001b[39m=\u001b[39mrequest_id,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=161'>162</a>\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=162'>163</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=164'>165</a>\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=165'>166</a>\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py?line=166'>167</a>\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=277'>278</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=278'>279</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=279'>280</a>\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=286'>287</a>\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=287'>288</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=288'>289</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=289'>290</a>\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=290'>291</a>\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=296'>297</a>\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=297'>298</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=298'>299</a>\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=299'>300</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=701'>702</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=702'>703</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=703'>704</a>\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=704'>705</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=705'>706</a>\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=706'>707</a>\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=707'>708</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=708'>709</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=709'>710</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=710'>711</a>\u001b[0m             result\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=711'>712</a>\u001b[0m             result\u001b[39m.\u001b[39mstatus_code,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=712'>713</a>\u001b[0m             result\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=713'>714</a>\u001b[0m             stream\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=714'>715</a>\u001b[0m         ),\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=715'>716</a>\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=716'>717</a>\u001b[0m     )\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=772'>773</a>\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=773'>774</a>\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=774'>775</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=775'>776</a>\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=776'>777</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/openai/api_requestor.py?line=777'>778</a>\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "model_engine = \"text-davinci-002\"\n",
    "temperature = 0\n",
    "\n",
    "max_tokens = 1000\n",
    "\n",
    "completions = openai.Completion.create(\n",
    "    engine=model_engine,\n",
    "    prompt='Hallo Welt',\n",
    "    max_tokens=max_tokens,\n",
    "    temperature=temperature\n",
    ")\n",
    "\n",
    "# Get the summary from the first completion\n",
    "summary = completions.choices[0].text\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2091, 1136, 1143, 13002, 1107, 1103, 5707, 1104, 16678, 1116, 117, 1111, 1152, 1132, 11515, 1105, 3613, 1106, 4470, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load pre-trained tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "encoded_input = tokenizer(\"Do not meddle in the affairs of wizards, for they are subtle and quick to anger.\")\n",
    "encoded_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLaMa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6dcb8e8a5bf4140a9914bad489e62da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3df38a07e84a899bbc0fe1559d7840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/33.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b11b3cf185b4c79bd03bce3cbd0c933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327372e4a81642fc840ced3ef24dae93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00003.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m----> 3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNousResearch/Llama-2-13b-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py:807\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=804'>805</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=805'>806</a>\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=806'>807</a>\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=807'>808</a>\u001b[0m         model,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=808'>809</a>\u001b[0m         model_classes\u001b[39m=\u001b[39mmodel_classes,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=809'>810</a>\u001b[0m         config\u001b[39m=\u001b[39mconfig,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=810'>811</a>\u001b[0m         framework\u001b[39m=\u001b[39mframework,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=811'>812</a>\u001b[0m         task\u001b[39m=\u001b[39mtask,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=812'>813</a>\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=813'>814</a>\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=814'>815</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=816'>817</a>\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/__init__.py?line=817'>818</a>\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py:267\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=260'>261</a>\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=261'>262</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=262'>263</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to load the model with Tensorflow.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=263'>264</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=265'>266</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=266'>267</a>\u001b[0m     model \u001b[39m=\u001b[39m model_class\u001b[39m.\u001b[39mfrom_pretrained(model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=267'>268</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/pipelines/base.py?line=268'>269</a>\u001b[0m         model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:516\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py?line=513'>514</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py?line=514'>515</a>\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py?line=515'>516</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py?line=516'>517</a>\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39mmodel_args, config\u001b[39m=\u001b[39mconfig, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py?line=517'>518</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py?line=518'>519</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py?line=519'>520</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py?line=520'>521</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py?line=521'>522</a>\u001b[0m )\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py:2786\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2782'>2783</a>\u001b[0m \u001b[39m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2783'>2784</a>\u001b[0m \u001b[39mif\u001b[39;00m is_sharded:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2784'>2785</a>\u001b[0m     \u001b[39m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2785'>2786</a>\u001b[0m     resolved_archive_file, sharded_metadata \u001b[39m=\u001b[39m get_checkpoint_shard_files(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2786'>2787</a>\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2787'>2788</a>\u001b[0m         resolved_archive_file,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2788'>2789</a>\u001b[0m         cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2789'>2790</a>\u001b[0m         force_download\u001b[39m=\u001b[39mforce_download,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2790'>2791</a>\u001b[0m         proxies\u001b[39m=\u001b[39mproxies,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2791'>2792</a>\u001b[0m         resume_download\u001b[39m=\u001b[39mresume_download,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2792'>2793</a>\u001b[0m         local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2793'>2794</a>\u001b[0m         token\u001b[39m=\u001b[39mtoken,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2794'>2795</a>\u001b[0m         user_agent\u001b[39m=\u001b[39muser_agent,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2795'>2796</a>\u001b[0m         revision\u001b[39m=\u001b[39mrevision,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2796'>2797</a>\u001b[0m         subfolder\u001b[39m=\u001b[39msubfolder,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2797'>2798</a>\u001b[0m         _commit_hash\u001b[39m=\u001b[39mcommit_hash,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2798'>2799</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2800'>2801</a>\u001b[0m \u001b[39m# load pt weights early so that we know which dtype to init the model under\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/modeling_utils.py?line=2801'>2802</a>\u001b[0m \u001b[39mif\u001b[39;00m from_pt:\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py:1026\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1022'>1023</a>\u001b[0m \u001b[39mfor\u001b[39;00m shard_filename \u001b[39min\u001b[39;00m tqdm(shard_filenames, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading shards\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1023'>1024</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1024'>1025</a>\u001b[0m         \u001b[39m# Load from URL\u001b[39;00m\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1025'>1026</a>\u001b[0m         cached_filename \u001b[39m=\u001b[39m cached_file(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1026'>1027</a>\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1027'>1028</a>\u001b[0m             shard_filename,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1028'>1029</a>\u001b[0m             cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1029'>1030</a>\u001b[0m             force_download\u001b[39m=\u001b[39mforce_download,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1030'>1031</a>\u001b[0m             proxies\u001b[39m=\u001b[39mproxies,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1031'>1032</a>\u001b[0m             resume_download\u001b[39m=\u001b[39mresume_download,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1032'>1033</a>\u001b[0m             local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1033'>1034</a>\u001b[0m             token\u001b[39m=\u001b[39mtoken,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1034'>1035</a>\u001b[0m             user_agent\u001b[39m=\u001b[39muser_agent,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1035'>1036</a>\u001b[0m             revision\u001b[39m=\u001b[39mrevision,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1036'>1037</a>\u001b[0m             subfolder\u001b[39m=\u001b[39msubfolder,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1037'>1038</a>\u001b[0m             _commit_hash\u001b[39m=\u001b[39m_commit_hash,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1038'>1039</a>\u001b[0m         )\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1039'>1040</a>\u001b[0m     \u001b[39m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1040'>1041</a>\u001b[0m     \u001b[39m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=1041'>1042</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py:428\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=424'>425</a>\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=425'>426</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=426'>427</a>\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=427'>428</a>\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=428'>429</a>\u001b[0m         path_or_repo_id,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=429'>430</a>\u001b[0m         filename,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=430'>431</a>\u001b[0m         subfolder\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(subfolder) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m subfolder,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=431'>432</a>\u001b[0m         repo_type\u001b[39m=\u001b[39mrepo_type,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=432'>433</a>\u001b[0m         revision\u001b[39m=\u001b[39mrevision,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=433'>434</a>\u001b[0m         cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=434'>435</a>\u001b[0m         user_agent\u001b[39m=\u001b[39muser_agent,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=435'>436</a>\u001b[0m         force_download\u001b[39m=\u001b[39mforce_download,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=436'>437</a>\u001b[0m         proxies\u001b[39m=\u001b[39mproxies,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=437'>438</a>\u001b[0m         resume_download\u001b[39m=\u001b[39mresume_download,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=438'>439</a>\u001b[0m         token\u001b[39m=\u001b[39mtoken,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=439'>440</a>\u001b[0m         local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=440'>441</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=441'>442</a>\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=442'>443</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=443'>444</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are trying to access a gated repo.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mMake sure to request access at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=444'>445</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://huggingface.co/\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m and pass a token having permission to this repo either \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=445'>446</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/transformers/utils/hub.py?line=446'>447</a>\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py?line=114'>115</a>\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py?line=115'>116</a>\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py?line=117'>118</a>\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py:1364\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=1360'>1361</a>\u001b[0m \u001b[39mwith\u001b[39;00m temp_file_manager() \u001b[39mas\u001b[39;00m temp_file:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=1361'>1362</a>\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mdownloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url, temp_file\u001b[39m.\u001b[39mname)\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=1363'>1364</a>\u001b[0m     http_get(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=1364'>1365</a>\u001b[0m         url_to_download,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=1365'>1366</a>\u001b[0m         temp_file,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=1366'>1367</a>\u001b[0m         proxies\u001b[39m=\u001b[39mproxies,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=1367'>1368</a>\u001b[0m         resume_size\u001b[39m=\u001b[39mresume_size,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=1368'>1369</a>\u001b[0m         headers\u001b[39m=\u001b[39mheaders,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=1369'>1370</a>\u001b[0m         expected_size\u001b[39m=\u001b[39mexpected_size,\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=1370'>1371</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=1372'>1373</a>\u001b[0m \u001b[39mif\u001b[39;00m local_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=1373'>1374</a>\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStoring \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m in cache at \u001b[39m\u001b[39m{\u001b[39;00mblob_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py:541\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=530'>531</a>\u001b[0m     displayed_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(…)\u001b[39m\u001b[39m{\u001b[39;00mdisplayed_name[\u001b[39m-\u001b[39m\u001b[39m20\u001b[39m:]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=532'>533</a>\u001b[0m progress \u001b[39m=\u001b[39m tqdm(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=533'>534</a>\u001b[0m     unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=534'>535</a>\u001b[0m     unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=538'>539</a>\u001b[0m     disable\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m(logger\u001b[39m.\u001b[39mgetEffectiveLevel() \u001b[39m==\u001b[39m logging\u001b[39m.\u001b[39mNOTSET),\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=539'>540</a>\u001b[0m )\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=540'>541</a>\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m):\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=541'>542</a>\u001b[0m     \u001b[39mif\u001b[39;00m chunk:  \u001b[39m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/huggingface_hub/file_download.py?line=542'>543</a>\u001b[0m         progress\u001b[39m.\u001b[39mupdate(\u001b[39mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/requests/models.py?line=813'>814</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/requests/models.py?line=814'>815</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/requests/models.py?line=815'>816</a>\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/requests/models.py?line=816'>817</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/requests/models.py?line=817'>818</a>\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py:628\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=625'>626</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=626'>627</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=627'>628</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread(amt\u001b[39m=\u001b[39mamt, decode_content\u001b[39m=\u001b[39mdecode_content)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=629'>630</a>\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=630'>631</a>\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=563'>564</a>\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=565'>566</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=566'>567</a>\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=567'>568</a>\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=568'>569</a>\u001b[0m         flush_decoder \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=529'>530</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=530'>531</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=531'>532</a>\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/site-packages/urllib3/response.py?line=532'>533</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/http/client.py?line=462'>463</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/http/client.py?line=463'>464</a>\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/http/client.py?line=464'>465</a>\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/http/client.py?line=465'>466</a>\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mread(amt)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/http/client.py?line=466'>467</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/http/client.py?line=467'>468</a>\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/http/client.py?line=468'>469</a>\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/http/client.py?line=469'>470</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/socket.py?line=703'>704</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/socket.py?line=704'>705</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/socket.py?line=705'>706</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39mrecv_into(b)\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/socket.py?line=706'>707</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/socket.py?line=707'>708</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py?line=1273'>1274</a>\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py?line=1274'>1275</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py?line=1275'>1276</a>\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py?line=1276'>1277</a>\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py?line=1277'>1278</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py?line=1278'>1279</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py?line=1279'>1280</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py?line=1131'>1132</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py?line=1132'>1133</a>\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py?line=1133'>1134</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py?line=1134'>1135</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/PaperGPT/lib/python3.11/ssl.py?line=1135'>1136</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"NousResearch/Llama-2-13b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f427bc22af4c9850908f551436beb1ee403e4a3e91288f61f96351fd51c52d89"
  },
  "kernelspec": {
   "display_name": "Python 3.11.4 ('PaperGPT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
